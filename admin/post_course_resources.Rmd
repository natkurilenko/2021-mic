---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.3
  kernelspec:
    display_name: Bash
    language: bash
    name: bash
---

# Overview
1. [Personal Notebooks](#Maintaining-Personal-Files): Downloading notebooks that you modified
2. [MIC Course Material](#Accessing-Course-Material): Downloading official course material: notebooks, lecture slides, etc
3. [Course Data](#Course-Data): How to download the data we used in the MIC Course
5. [MIC Computing Environment](#MIC-Computing-Environment): Downloading and running the HTS Image in Docker or Singularity

<!-- #region -->
# High Priority

If you have **created or modified files** in your Jupyter container that you would like to preserve, we recommend that you follow the instructions for [Maintaining Personal Files](#Maintaining-Personal-Files).
-   We recommend you do this before *as soon as possible*, certainly by July 2nd, 2021. After July 2nd, 2021 the container system we used during the course will be shut down.
-   Keep in mind that you only need to worry about this for files that you have  **created or modified**.  The course material that we created and shared with you will continue to be publicly available.

## Important Notes

See details below, but please keep the following in mind:
1.  The course material will remain in the [2021 MIC Course Gitlab Repository](https://gitlab.oit.duke.edu/mic-course/2021-mic) and will be publicly available, in perpetuity (or as long as <https://gitlab.oit.duke.edu/> continues to exist), regardless of your affiliation with Duke (or lack thereof). See below for details.
2.  The configuration and build information for the course Docker container will remain in the [Jupyter MIC 2021 Gitlab Repository](https://gitlab.oit.duke.edu/mic-course/jupyter-MIC-2021) and will be publicly available, in perpetuity (or as long as <https://gitlab.oit.duke.edu/> continues to exist), regardless of your affiliation with Duke (or lack thereof).
3. The 2021 MIC Jupyter Docker image will remain in the [Jupyter MIC 2021 DockerHub Repository](https://hub.docker.com/repository/docker/miccourse/jupyter-mic-2021) and will be publicly available, in perpetuity (or as long as <https://hub.docker.com> continues to exist and host free repositories), regardless of your affiliation with Duke (or lack thereof).

# Maintaining Personal Files

## Tar and Download

### Tarring


#### Tarring: Only Notebooks
If you only want to get *notebooks and shell scripts*, you could use the following to only grab the notebooks from 2021-mic. This will skip a lot of stuff you probably don't want. This archive file will be in your home directory and will be named 2021-mic-notebooks.tar.gz
<!-- #endregion -->

```{bash}
find ~/2021-mic  \
    -not -path "*/.ipynb_checkpoints/*" \
    -name "*.Rmd" \
    -o -name "*.sh" \
    | tar -cvzf ~/2021-mic-notebooks.tar.gz -T -
```

#### Tarring: Only Notebooks with a common name

If you want only modified notebooks **and** you saved them with a standard naming scheme, e.g. leaving `-Copy1` in the name, for example, renaming `demultiplex.Rmd` to `demultiplex-Copy1.Rmd`, you could use the following to only grab the modified files from 2021-mic

```{bash}
find ~/2021-mic \
    -name "*-Copy1*" \
    -not -path "*/.ipynb_checkpoints/*" \
    | tar -cvzf ~/2021-mic-copy1.tar.gz -T -
```

<!-- #region -->
### Downloadng the tarball

Now you can do one of the following to download the tarball to your laptop. 

1. Click on the "Jupyter" logo above to open the Jupyter file browser
2. Naviagte your way to the directory where you saved the tarball.  The tarball should be in the toplevel directory, which is usually what opens when you click the Jupyter logo, but if not, you can click on the folder icon near the top of the file browser
3. Click the checkbox next to `2021-mic-notebooks.tar.gz`
4. Click the *Download* button near the top of the Jupyter window to download it.

### Unpacking the tarball
On a Mac you can "untar" by double clicking on the file in finder, or at the terminal with the command `tar -zxf 2021-mic-notebooks.tar.gz`.

On Windows, you can download software that will do it, such as [7-Zip](http://www.7-zip.org/)

> If you named your tarball, you should substitute whatever name you used above.

# Accessing Course Material

You can access the course material in three different ways:
1.  You can browse and download the material from the [2021 MIC Course Repository](https://gitlab.oit.duke.edu/mic-course/2021-mic) by clicking on the Download button, which is right next to the blue **Clone** button. It will give you a choice of format you want. The best options are probably "zip" or "tar.gz"
2.  You can **clone** the repo using git: `git clone https://gitlab.oit.duke.edu/mic-course/2021-mic.git`

# Course Data
The data we used in the 2021 MIC course was from GEO Accession number GSE159344.  The FASTQ files were downloaded from SRA and the metadata table was built using information from GEO and SRA. Both of these were done with the [download_data_sra.Rmd](../bioinformatics/setup/download_data_sra.Rmd) script.


# MIC Computing Environment
The computing environment that we used in the MIC course was based on a Docker image. The MIC Course Docker image is available [here on DockerHub](https://hub.docker.com/repository/docker/miccourse/jupyter-mic-2021). If you install Docker, the image can be downloaded with the command `docker pull miccourse/jupyter-mic-2021:2021_final`.  The Dockerfile (i.e. recipe) used to build it is in the [Jupyter MIC 2021 GitLab Repository](https://gitlab.oit.duke.edu/mic-course/jupyter-MIC-2021). 

There are detailed instuctions on the [Jupyter MIC 2021 GitLab Repository](https://gitlab.oit.duke.edu/mic-course/jupyter-MIC-2021) for several different ways to run this computing environment:

1. [Run on a SLURM cluster](https://gitlab.oit.duke.edu/mic-course/jupyter-MIC-2021#running-the-course-image-on-a-slurm-cluster), like the [Duke Computer Cluster](https://rc.duke.edu/dcc/).
2. [Run on your local computer](https://gitlab.oit.duke.edu/mic-course/jupyter-MIC-2021#run-image-on-your-local-computer)
3. If you are at Duke, you can run things on the Duke Computer Cluster by cloning the git repo and cd'ing into the course repo directory, then following the [Run on a SLURM cluster](https://gitlab.oit.duke.edu/mic-course/jupyter-MIC-2021#running-the-course-image-on-a-slurm-cluster) instructions, but substituting the following for the command in step 3
```
export SINGULARITY_CACHEDIR="/work/${USER}/singularity_cache"; srun --cpus-per-task=20 --mem=50G admin/run_singularity/run_singularity_jupyter.sh
```

> It takes about 40GB of RAM to run the notebooks as they are. It might be less if you run with fewer threads.

## Running the Docker Image Elsewhere

### Running on your local machine
#### Quick Start
The script that was demonstrated in class for installing the course Jupyter image and downloading the hts2019-notebooks repo is at  <https://gitlab.oit.duke.edu/hts2019/hts2019-notebooks/blob/master/computing/reproducible_demo.sh>.  It should work in any environment that meets the requirements listed below.  Run it like this (on your local computer or server):

```
bash reproducible_demo.sh
```
Once you start the Jupyter container it will continue running, even if you are not actively using Jupyter.

For detailed instructions see [Install docker](#Install-docker) and [Run docker](#Run-docker) below.  If this 

##### Requirements

-   git
-   docker
-   bash

###### Install docker

To run a container on your local machine or laptop, download the docker program from <https://www.docker.com>.  There is a tab at the top of the page that says 'Get Docker'. You can run it on OS X, Windows, and Linux:
- [Docker for Mac](https://docs.docker.com/docker-for-mac/) 
- [Docker for Windows](https://docs.docker.com/docker-for-windows/)
- [Linux: Docker Community Edition](https://store.docker.com/search?type=edition&offering=community&operating_system=linux)



#### Run docker
If you successfully ran `reproducible_demo.sh`, as described above, you can skip this step and go on to [Open the notebook in your browser
](#Open-the-notebook-in-your-browser)

Once you have the docker program installed, open the program (you should get a terminal screen with command line). Enter the command:
```
docker pull dukehtscourse/jupyter-hts-2019
```

This will pull down the course docker image from dockerhub. It may take a few minutes. Next, run the command to start a container:
```
docker run --name hts-course -v YOUR_DIRECTORY_WITH_COURSE_MATERIAL:/home/jovyan/work \
-d -p 127.0.0.1\:9999\:8888 \
-e PASSWORD="YOUR_CHOSEN_NOTEBOOK_PASSWORD" \
-e NB_UID=1000 \
-t dukehtscourse/jupyter-hts-2019
```
The most important parts of this verbiage are the `YOUR_DIRECTORY_WITH_COURSE_MATERIALS` and `YOUR_CHOSEN_NOTEBOOK_PASSWORD`. 
-   `YOUR_DIRECTORY_WITH_COURSE_MATERIALS` (Bind mounting): The directory name is the one you extracted your course materials into. So, if you put them in your home directory, it might look something like: `-v /home/janice/HTS2019-notebooks:/home/jovyan/work`
-   `YOUR_CHOSEN_NOTEBOOK_PASSWORD`: The password is whatever you want to use to password protect your notebook. Now, this command is running the notebook so that it is only 'seen' by your local computer - no one else on the internet can access it, and you cannot access it remotely, so the password is a bit of overkill. Use it anyway. An example might be: `-e PASSWORD="Pssst_this_is_Secret"` except that this is a terrible password and you should follow standard rules of not using words, include a mix of capital and lowercase and special symbols. etc.
-   `-d -p 127.0.0.1\:9999\:8888` part of the command is telling docker to run the notebook so that it is only visible to the local machine. It is absolutely possible to run it as a server to be accessed across the web - but there are some security risks associated, so if you want to do this proceed with great caution and get help.

#### Open the notebook in your browser

Open a browser and point it to http://127.0.0.1:9999
You should get to a Jupyter screen asking for a password. This is the password you created in the docker run command.
Now, you should be able to run anything you like from the course. Depending on your laptop's resources (RAM, cores), this might be slow, so be aware and start by testing only one file (vs the entire course data set).

#### Stopping Docker
The container will continue running, even if you do not have Jupyter open in a web browser.  If you don't plan to use it for a while, you might want to shut it down so it isn't using resources on your computer.  Here are two ways to do that:
##### Kitematic
Included in the [Docker for Mac](https://docs.docker.com/docker-for-mac/) and the [Docker for Windows](https://docs.docker.com/docker-for-windows/) installations.
   
##### Commandline
You may want to familiarize yourself with the following Docker commands.
-   `docker stop`
-   `docker rm`
-   `docker ps -a`
-   `docker images`
-   `docker rmi`

#### Windows Note
These instructions have not been tested in a Windows environment.  If you have problems with them, please give us feedback

### Running on a server
To run on a remote server you will want to use a slightly different command from above, because you *will need to connect remotely*:

```
docker run --name hts-course \
-v YOUR_DIRECTORY_WITH_COURSE_MATERIAL:/home/jovyan/work \
-d -p 8888:8888 \
-e USE_HTTPS="yes" \
-e PASSWORD="YOUR_CHOSEN_NOTEBOOK_PASSWORD" \
-e NB_UID=1000 \
-t dukehtscourse/jupyter-hts-2019
```

#### Running on a Duke server (Duke Affiliates)

If you want to use the HTS Docker container for research, contact Mark Delong and the research computing people. Andy Ingham (one of Mark DeLong's guys) can help with setup of a research VM with the HTS Docker container. If there is enough interest we could also look at having an option for an HTS image that could be automatically provisioned as part of the Research Toolkits/RAPID service for Duke researchers in general.

#### Running on a non-Duke server

Sys admins at other institution may be able to help set you up with compute resources if you let them know that you want to use a dockerhub image.  Mark McCahill (OIT Wizard, class 50, and the person who keeps our course containers humming along) <mark.mccahill@duke.edu> has generously offered to consult with IT people at other institutions to get you up and running.  You can also run Docker images in AWS or Azure cloud environments.  Mark McCahill can probably give you some pointers here too.

### Running the Course Image with Singularity
Docker requires root permissions to run, so you are unlikely to be able to run Docker on a computer that you are not fully in control of.  As an alternative you can run the course image with [Singularity](https://sylabs.io/singularity/), another container system. Singularity is similar to Docker, and can run Docker images, but you do not need special permissions to run Singularity images *or* Docker images with Singularity (as long as Singularity is actually installed on the computer).

The following command uses Singularity to start up a container from the course Jupyter image.
```
export USE_HTTPS=yes; \
    singularity exec docker://dukehtscourse/jupyter-hts-2019 \
    /usr/local/bin/start-notebook.sh 
```

#### Install Singularity
Here are instructions for installing:

- [Singularity version 2.6](https://sylabs.io/guides/2.6/user-guide/quick_start.html#quick-installation-steps)
- [Singularity version 3.2](https://sylabs.io/guides/3.2/user-guide/quick_start.html#quick-installation-steps)
- [Singularity Desktop for macOS (Alpha Preview)](https://sylabs.io/singularity-desktop-macos/)


# Select Duke Computing Resources

-   [Duke Research Computing Website](https://rc.duke.edu)
-   [Research Computing Links on OIT Website](https://oit.duke.edu/what-we-do/services/research-computing)

## Individual Virtual Machines

-   [Virtual Computing Manager](https://oit.duke.edu/help/articles/vcm-how-use-virtual-computing-manager): Duke offers free small VMs (2 core, 2GB RAM) all affiliates through a system called VCM.  For running the Jupyter containers you will want some version of Linux, such as "Ubuntu 16.04"
-   [Research Toolkits](https://oit.duke.edu/what-we-do/applications/research-toolkits): Duke faculty researchers have access to moderate size VMs (4 core, 32GB RAM)

## Clusters

-   [Duke Compute Cluster](https://rc.duke.edu/the-duke-compute-cluster/)
-   [HARDAC](https://genome.duke.edu/cores-and-services/computational-solutions/compute-environments-genomics)

# Assorted Notes on Approaches to Reproducible Analysis

## Scripting Options

I have used shell scripts, makefiles, Jupyter notebooks, and Rmarkdown notebooks as “master scripts” for running complex analyses.  My current preference is for Rmarkdown notebooks.  Jupyter and Rmarkdown let you combine code from different languages in a single notebook, so you can have a bash cell followed by an R cell followed by a python cell.  You can’t put other languages in shell scripts or makefiles, so if you want to combine multiple languages with these, you need to put that code in its own script and run that script similar to how you would run a binary executable.

One thing I like about Rmarkdown is how easy it is to generate good looking reports/manuscripts.

## Singularity

I switched from Docker to Singularity for several reasons that are mostly summed up by the fact that Singularity was designed for use in a research environment.  As far as you are concerned the most important issue is that you have to have root to run Docker on a machine, so no cluster sysadmin will ever let you run your own Docker container.  Singularity runs fine in user space and is installed on both of the Duke clusters I have access to.  If you need to convince the cluster admin to install it, see this: <http://singularity.lbl.gov/install-request>.

I put together these notes about [getting started with Singularity](https://gist.github.com/granek/6f492ed1593bcc0c1c6cafe242a2e5d4).  They were intended to run on a Duke VCM or RAPID VM, but should work on any machine where you have root.  If you don’t have root on any linux machine, you can try to run Singularity on your local machine: <http://singularity.lbl.gov/install-mac> or <http://singularity.lbl.gov/install-windows>

## Etc

I almost never run anything locally on my computer, I do everything through web interfaces (RStudio Server) and command line session over ssh, both running on remote servers.  I end up running most of my research projects on the Duke VCM or RAPID machines, which I can get away with because microbial datasets tend to be relatively modest.  

These days when I start a new project, I prepare a Singularity Recipe with the software I expect to need and build a Singularity image from it.  I usually include RStudio Server in these images so I can use that interface to develop Rmarkdown notebooks and run the analysis.  For the occasional project where I need a bigger machine I still build the image on my VCM or RAPID machine (building a singularity image requires sudo, and these are the only machines where I have root), and copy the image over to a bigger server.  I have access to one biggish server where I can run RStudio Server from a Singularity image, but I don’t think the clusters on campus allow this, so I am stuck working over an ssh session.

All my scripts, config files, metadata, and Singularity Recipes/Dockerfiles live in a git repo that is synced to Github/Bitbucket/Gitlab.  This makes it easy to move this stuff between servers if I need to upgrade.  I usually end up having to rsync data and Singularity images between servers, because only the VCM and RAPID servers can share storage.  If I do this, I will tend to move everything over to the bigger server, instead of trying to work in two places, because it gets confusing. The one exception is that if I need to update the singularity image that has to be done on one of the VMs I control.

As much as possible, I avoid running things on clusters because they make things more complicated: I can’t use RStudio and I have to fiddle with SLURM.  When I do need to work on a machine that won’t allow RStudio, I will often edit files with Emacs running locally (because it is set up how I like and has a nice mac os interface) using tramp-mode.  Several other text editors allow you to edit remote files over ssh.
<!-- #endregion -->
