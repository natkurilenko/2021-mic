---
title: "Download Data"
output:
  html_document:
    toc: false
---

```{r}
library(GEOquery)
library(dplyr)
library(rentrez)
library(readr)
library(stringr)
library(fs)
library(R.utils)
library(purrr)
library(tibble)
library(tools)
library(tidyr)

sra_tmp=file.path("/workspace", "nci_r25", "sra_tmp"); dir.create(sra_tmp, recursive = TRUE)
sra_dir=file.path("/workspace", "nci_r25", "sra_data"); dir.create(sra_dir, recursive = TRUE)
accessions_file = file.path(sra_dir,"accession_table.csv")

bioproject_accession="PRJNA668393"
geo_accession="GSE159344"

library(here)
srafastq_md5file = here("info/sra_fastq_md5checksums.txt")
```

# Make Metadata Table with SRA and GEO Accesion Numbers
## Get SRA Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r}
entrez_search(db="sra", term=bioproject_accession,retmax=1000) ->
  sra_search

# check that we got everything
stopifnot(sra_search[["count"]]==length(sra_search[["ids"]]))

entrez_fetch(db="sra", id=sra_search[["ids"]], rettype="runinfo") %>%
  read_csv %>%
  dplyr::select(Run, Experiment, SampleName) %>%
  filter(Run!="Run") ->
  sra_df
sra_df
```

## Get GEO Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r}
getGEO(geo_accession,GSEMatrix=TRUE) ->
  gse
pData(gse[[1]]) %>%
  dplyr::select(geo_accession,
                title,
                `cell line:ch1`,
                `treatment:ch1`) %>%
  rename_with(str_remove, .cols = everything(), ":ch1") %>%
  rename_with(str_replace_all, .cols = everything(), " ", "_") ->
  geo_df
geo_df
```

## Join SRA and GEO Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r}
right_join(sra_df, 
          geo_df, 
          by=c("SampleName"="geo_accession")) ->
  accessions_with_meta

accessions_with_meta %>%
  filter(str_detect(treatment, "anti-PD-1"))

# Drop triple therapy samples
accessions_with_meta %>%
  filter(str_detect(treatment, 
                    fixed("anti-PD-1 + ablative fractional photothermolysis + imiquimod"),
                    negate=TRUE)) ->
  accessions_with_meta

accessions_with_meta %>%
  rename(cell_line_long=cell_line, 
         treatment_long=treatment) %>%
  separate(col=title,
           sep=" ",
           into=c("cell_line", "treatment", "replicate")) ->
  accessions_with_meta

accessions_with_meta %>%
  write_csv(accessions_file)
accessions_with_meta
```



# Download FASTQs from SRA
## Make NCBI config File

  - https://github.com/ncbi/sra-tools/issues/409#issuecomment-801344783
    - https://github.com/ncbi/sra-tools/blob/e2117adf073f748cc48412c55acdc9bfe679a2d1/build/docker/Dockerfile.delite#L50-L52    

```{bash}
NCBI_CONFIG=${HOME}/.ncbi/user-settings.mkfg
if [ -f "$NCBI_CONFIG" ]; then
    echo "$NCBI_CONFIG exists."
    cat $NCBI_CONFIG
else 
    echo "Need to make $NCBI_CONFIG . . ."
    mkdir -p $(basename $NCBI_CONFIG)
    vdb-config --set "/LIBS/GUID =`uuidgen`"
    vdb-config --set "/repository/user/main/public/root =/workspace/sra_cache" 
    cat $NCBI_CONFIG
fi
```

## fasterqDump Definition
```{r}
fasterqDump = function(accession,
                       outdir,
                       tempdir = NULL,
                       gzip = TRUE,
                       md5_df = NULL) {
  # Check if file is downloaded and OK
  accession %>%
    path_ext_set("fastq") ->
    fastq_file
  
  fastq_file %>%
    paste0(".gz") ->
    fastq_gz_file
  
  fastq_gz_file %>%
    file.path(outdir, .) ->
    fastq_gz_path
  
  fastq_file %>%
    file.path(outdir, .) ->
    fastq_path
  
  if (gzip == TRUE) {
    final_path = fastq_gz_path
  }
  else {
    final_path = fastq_path
  }
  
  if(!is.null(md5_df)){
    final_path %>%
      basename ->
      final_file
    
    final_path %>%
      md5sum ->
      observed_md5
    
    md5_df %>%
      filter(filename == final_file) %>%
      pull(md5sum) ->
      true_md5
    
    if (file.exists(final_path) && true_md5 == observed_md5){
      cat("MD5sum match", fastq_gz_path, true_md5, fill = TRUE)
      return(final_path)
    }
  }
  cat("Need to download", accession, fill = TRUE)
  fasterq_args =  c(accession, "--outdir", outdir)
  if (!is.null(tempdir)){
    # dir.create(tempdir, recursive = TRUE)
    fasterq_args =  c(fasterq_args, "--temp", tempdir)
  }
  system2(command="fasterq-dump",
          args=fasterq_args,
          stdout = TRUE,
          stderr = TRUE) ->
    std_err_out
  
  print(std_err_out)
  
  if (gzip == TRUE){
    if (file.exists(fastq_path)){
      final_path = gzip(fastq_path)
    } else {
      # check for paired reads
      r1_path = str_replace(fastq_path,".fastq", "_1.fastq")
      r2_path = str_replace(fastq_path,".fastq", "_2.fastq")
      final_path = c()
      if (file.exists(r1_path)){
        final_path = c(final_path, gzip(r1_path))
      }
      if (file.exists(r2_path)){
        final_path = c(final_path, gzip(r2_path))
      }
    }
  }
  return(final_path)
}
```


```{r eval=FALSE, include=FALSE}

# fasterqDump(accession="SRR12804463", outdir=sra_dir, tempdir=sra_tmp)
```


## Load "True" MD5sums from file
```{r}
srafastq_md5file %>%
  read_delim(delim=" ", 
             trim_ws = TRUE,
             col_names = c("md5sum", "filename")) ->
  srafastq_md5s
```

```{r}
sra_df %>%
  pull(Run) %>%
  map(function(x) fasterqDump(accession=x, outdir=sra_dir, tempdir=sra_tmp, md5_df=srafastq_md5s)) ->
  downloaded_fastqs
```


## Generate MD5 table
Only need to do this at the beginning
```{r}
downloaded_fastqs %>%
  unlist %>%
  md5sum %>%
  enframe %>%
  dplyr::rename(fullpath=name, md5sum=value) %>%
  mutate(filename=basename(fullpath)) %>%
  select(md5sum, filename) %>%
  write_delim(file.path(srafastq_md5file), col_names = FALSE)
```

# SessionInfo
```{r}
sessionInfo()
```
