---
title: "Download Data"
output:
  html_document:
    toc: false
---

```{r}
library(GEOquery)
library(dplyr)
library(rentrez)
library(readr)
library(stringr)
library(fs)
library(R.utils)
library(purrr)
library(tibble)
library(tools)
library(tidyr)
library(here)

# sra_tmp=file.path("/workspace", "sra_tmp"); dir.create(sra_tmp, recursive = TRUE)
# sra_dir=file.path("/data", "sra_data"); dir.create(sra_dir, recursive = TRUE)
scratch_dir=path.expand("~/scratch")
sra_cache=file.path(scratch_dir, "sra_cache")
sra_tmp=file.path(scratch_dir, "sra_tmp"); dir.create(sra_tmp, recursive = TRUE)
sra_dir=file.path(scratch_dir, "sra_data"); dir.create(sra_dir, recursive = TRUE)
ncbi_config = path.expand("~/.ncbi/user-settings.mkfg")

accessions_file = file.path(sra_dir,"accession_table.csv")

bioproject_accession="PRJNA668393"
geo_accession="GSE159344"

srafastq_md5file = here("info/sra_fastq_md5checksums.txt")
```

# Make Metadata Table with SRA and GEO Accesion Numbers
## Get SRA Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r}
entrez_search(db="sra", term=bioproject_accession,retmax=1000) ->
  sra_search

# check that we got everything
stopifnot(sra_search[["count"]]==length(sra_search[["ids"]]))

entrez_fetch(db="sra", id=sra_search[["ids"]], rettype="runinfo") %>%
  read_csv %>%
  dplyr::select(Run, Experiment, SampleName) %>%
  filter(Run!="Run") ->
  sra_df
sra_df
```

## Get GEO Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo

```{r}
getGEO(geo_accession,GSEMatrix=TRUE, parseCharacteristics=FALSE, getGPL=FALSE) ->
  gse
pData(gse[[1]]) %>%
  dplyr::select(geo_accession,
                title,
                `cell line:ch1`,
                `treatment:ch1`) %>%
  rename_with(str_remove, .cols = everything(), ":ch1") %>%
  rename_with(str_replace_all, .cols = everything(), " ", "_") ->
  geo_df
geo_df
```

## Join SRA and GEO Metadata
This chunk doesn't need to be run because info is loaded from a file in the repo
```{r}
right_join(sra_df, 
          geo_df, 
          by=c("SampleName"="geo_accession")) ->
  accessions_with_meta

accessions_with_meta %>%
  filter(str_detect(treatment, "anti-PD-1"))

# Drop triple therapy samples
accessions_with_meta %>%
  filter(str_detect(treatment, 
                    fixed("anti-PD-1 + ablative fractional photothermolysis + imiquimod"),
                    negate=TRUE)) ->
  accessions_with_meta

accessions_with_meta %>%
  rename(cell_line_long=cell_line, 
         treatment_long=treatment) %>%
  separate(col=title,
           sep=" ",
           into=c("cell_line", "treatment", "replicate")) ->
  accessions_with_meta

accessions_with_meta %>%
  write_csv(accessions_file)
accessions_with_meta
```
# Download FASTQs from SRA
## Make NCBI config File

  - https://github.com/ncbi/sra-tools/issues/409#issuecomment-801344783
    - https://github.com/ncbi/sra-tools/blob/e2117adf073f748cc48412c55acdc9bfe679a2d1/build/docker/Dockerfile.delite#L50-L52    

```{r}
if(file.exists(ncbi_config)){
    print(paste("NCBI config exists:", ncbi_config))

    ncbi_config %>%
        read_file %>%
        cat
} else {
    print(paste("Need to make NCBI config:", ncbi_config))
#     mkdir -p $(basename $NCBI_CONFIG)
    ncbi_config %>%
        dirname %>%
        dir.create(recursive = TRUE)

    system2("vdb-config", 
        args = paste0("--set ", '"/LIBS/GUID =', uuid::UUIDgenerate(),'"'),
        stdout = TRUE,stderr = TRUE)
    system2("vdb-config", 
        args = paste0("--set ", '"/repository/user/main/public/root =', sra_cache,'"'),
        stdout = TRUE,stderr = TRUE)

    ncbi_config %>%
        read_file %>%
        cat
}
```

## fasterqDump Definition
```{r}
fasterqDump = function(accession,
                       outdir,
                       tempdir = NULL,
                       gzip = TRUE,
                       md5_df = NULL) {
  warning("Might be  handling MD5sum check correctly for paired-end data??")
  # Check if file is downloaded and OK
  accession %>%
    path_ext_set("fastq") ->
    fastq_file
  
  fastq_file %>%
    paste0(".gz") ->
    fastq_gz_file
  
  fastq_gz_file %>%
    file.path(outdir, .) ->
    fastq_gz_path
  
  fastq_file %>%
    file.path(outdir, .) ->
    fastq_path
  
  if (gzip == TRUE) {
    final_path = fastq_gz_path
  }
  else {
    final_path = fastq_path
  }
  
  if(!is.null(md5_df)){
    final_path %>%
      basename ->
      final_file
    
    
    
    if (file.exists(final_path)){
        final_path %>%
            md5sum ->
            observed_md5
        md5_df %>%
          filter(filename == final_file) %>%
          pull(md5sum) ->
          true_md5

        if(true_md5 == observed_md5){
            cat("MD5sum match", fastq_gz_path, true_md5, fill = TRUE)
            return(final_path)
        }
    }
    else {
        # check for paired-end data
        accession %>%
            paste0("_1.fastq") %>%
            file.path(outdir, .) ->
            r1_fastq_path
        accession %>%
            paste0("_2.fastq") %>%
            file.path(outdir, .) ->
            r2_fastq_path
        if (gzip == TRUE) {
            r1_fastq_path
            final_r1_path = paste0(r1_fastq_path, ".gz")
            final_r2_path = paste0(r2_fastq_path, ".gz")
        } else {
            final_r1_path = r1_fastq_path
            final_r2_path = r2_fastq_path
        }
        if (file.exists(final_r1_path) &&
            file.exists(final_r2_path)){
            r1_observed_md5 = md5sum(final_r1_path)
            r2_observed_md5 = md5sum(final_r2_path)
                
            md5_df %>%
                filter(filename == basename(final_r1_path)) %>%
                pull(md5sum) ->
                r1_true_md5
            md5_df %>%
                filter(filename == basename(final_r2_path)) %>%
                pull(md5sum) ->
                r2_true_md5
            if(r1_true_md5 == r1_observed_md5 &&
               r2_true_md5 == r2_observed_md5){
                cat("MD5sum match", final_r1_path, r1_true_md5, fill = TRUE)
                cat("MD5sum match", final_r2_path, r2_true_md5, fill = TRUE)
                return(c(final_r1_path,final_r2_path))
            }
        }
    }
    }
  cat("Need to download", accession, fill = TRUE)
  fasterq_args =  c(accession, "--outdir", outdir)
  if (!is.null(tempdir)){
    # dir.create(tempdir, recursive = TRUE)
    fasterq_args =  c(fasterq_args, "--temp", tempdir)
  }
  system2(command="fasterq-dump",
          args=fasterq_args,
          stdout = TRUE,
          stderr = TRUE) ->
    std_err_out
  
  print(std_err_out)
  
  if (gzip == TRUE){
    if (file.exists(fastq_path)){
      final_path = gzip(fastq_path)
    } else {
      # check for paired reads
      r1_path = str_replace(fastq_path,".fastq", "_1.fastq")
      r2_path = str_replace(fastq_path,".fastq", "_2.fastq")
      final_path = c()
      if (file.exists(r1_path)){
        final_path = c(final_path, gzip(r1_path))
      }
      if (file.exists(r2_path)){
        final_path = c(final_path, gzip(r2_path))
      }
    }
  }
  return(final_path)
}
```


```{r include=FALSE, eval=FALSE}

# fasterqDump(accession="SRR12804463", outdir=sra_dir, tempdir=sra_tmp)
```


## Load "True" MD5sums from file
```{r}
srafastq_md5file %>%
  read_delim(delim=" ", 
             trim_ws = TRUE,
             col_names = c("md5sum", "filename")) ->
  srafastq_md5s
```

```{r}
# fasterqDump(accession="SRR12804463", outdir=sra_dir, tempdir=sra_tmp,md5_df=srafastq_md5s)
```

```{r}
accessions_with_meta %>%
  pull(Run) %>%
  map(function(x) fasterqDump(accession=x, outdir=sra_dir, tempdir=sra_tmp, md5_df=srafastq_md5s)) ->
  downloaded_fastqs
```


## Generate MD5 table
Only need to do this at the beginning
```{r}
if(!file.exists(srafastq_md5file)){
    downloaded_fastqs %>%
      unlist %>%
      md5sum %>%
      enframe %>%
      dplyr::rename(fullpath=name, md5sum=value) %>%
      mutate(filename=basename(fullpath)) %>%
      select(md5sum, filename) %>%
      write_delim(srafastq_md5file, col_names = FALSE)
    }
```

# SessionInfo
```{r}
sessionInfo()
```
